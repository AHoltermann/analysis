IN THE BEGINNING WAS THE FILE TREE
	.
	|-- condor
	|   |-- checkdone.sh
	|   |-- de2pa.csh
	|   |-- de2pa.job
	|   |-- de2pa_XEMC.csh
	|   |-- de2pa_XEMC.job
	|   |-- err/
	|   |-- g42rc.csh
	|   |-- g42rc.job
	|   |-- log/
	|   |-- make_g4.csh
	|   |-- make_g4.job
	|   |-- out/
	|   |-- pa2pr_XEMC.csh
	|   |-- rc2de.csh
	|   |-- rc2de.job
	|   |-- rc2de_XEMC.csh
	|   |-- rc2de_XEMC.job
	|   `-- submit.sh
	|-- data
	|   |-- de/
	|   |-- de_XEMC/
	|   |-- g4/
	|   |-- pa/
	|   |-- pa_XEMC/
	|   |-- pr_XEMC/
	|   |-- qa0/
	|   |-- qa0_XEMC/
	|   |-- qa1/
	|   |-- qa1_XEMC/
	|   |-- rc/
	|   |-- rcli0/
	|   |-- rcli0_XEMC/
	|   |-- rcli1/
	|   `-- rcli1_XEMC/
	|-- macro
	|   |-- de2pa.C
	|   |-- g42rc.C
	|   |-- globals.h
	|   |-- make_g4.C
	|   |-- pa2pr.C
	|   `-- rc2de.C
	|-- src
	|   |-- ClusterPeeler.C
	|   `-- ClusterPeeler.h
	`-- util
	    |-- make_everything.sh
	    |-- make_file_de.C
	    |-- make_file_pa.C
	    |-- make_file_pa.sh
	    |-- make_file_pa_XEMC.sh
	    |-- make_files_de.sh
	    |-- make_files_de_XEMC.sh
	    |-- make_table.sh
	    |-- make_table_de.sh
	    |-- make_table_de_XEMC.sh
	    |-- make_table_g4.sh
	    |-- make_table_g4_failures.sh
	    |-- make_table_pa.sh
	    |-- make_table_pa_XEMC.sh
	    |-- make_table_rc.sh
	    `-- make_table_rc_failures.sh
	
	in the beginning was the file tree,
	and the file tree was filled with code.
	
	but the file tree was barren
	because it was not filled with data.
	
	all data is generated by the code,
	and without the code is not any data generated.

GETTING STARTED
	to state the obvious.. if you have not yet read README, then
		
		$ less README
	
	the ultimate goal of all this code
	is to produce some plots,
	which translates into filling ./data/pr_XEMC/
	with some appropriate PDF files.
	
	first, i need to specify which energy/pseudorapidity/flavor values i am using.
	these are inserted into the code in ./util/make_table.sh
	so, run that script.
		
		$ cd util
		$ ./make_table.sh
	
	you just generated the text file ./util/table
		
		$ head -n 4 table
		000110322500 e- 3.2 25.
		000110322120 e- 3.2 21.2
		000110320820 e- 3.2 8.2
		000110320400 e- 3.2 4.0
		$ less table

MAKING GEANT4 SIMULATIONS
	generate the argument table..
		
		$ ./make_table_g4.sh
	
	you just generated ./util/table_g4
		
		$ head -n 4 table_g4
		G40001103225000.root e- 3.2 25.
		G40001103225001.root e- 3.2 25.
		G40001103225002.root e- 3.2 25.
		G40001103225003.root e- 3.2 25.
		$ less table_g4
	
	this table is read by ./condor/make_g4.job
	you should now be good to submit that job.
	
	you could do it manually, but i use ./condor/submit.sh
	submit.sh clears log/* and err/* and out/* before submitting new jobs,
	which can take a few tens of seconds.
	so, the script might seem to not do anything at first, but it is working.
		
		$ cd ../condor
		$ ./submit make_g4.
	
	these jobs can take a while to complete.. many hours, sometimes.
	you can check when things start finishing up by running ./condor/checkdone.sh
	if a job has not finished, it should tell you so.
	if all jobs have finished, it will return without printing.
		
		$ ./checkdone.sh
	
	if you want to do a good solid reliable check, do like
		
		$ condor_q $USER
	
	once everything is finished,
	you should probably check some of the logs,
	especially err/
		
		$ cat err/1
		$ cat err/10
		$ cat err/100
		$ cat log/900
		$ cat out/13
	
	if most jobs seems okay,
	it is time to inspect the generated files.
	an easy, automated way to do this
	is to run ./util/make_table_g4_failures.sh
		
		$ cd ../util
		$ ./make_table_g4_failure.sh
		$ cat table_g4
	
	make_table_g4_failures tries to inspect the output GEANT4 DST files
	and make a list of them that seem to have been generated incorrectly.
	then, table_g4 is regenerated to reflect which files have been improperly created.
	so, if table_g4 is *not* empty after running make_table_g4_failures.sh,
	then you should re-submit make_g4.job
		
		$ cd ../condor
		$ ./submit.sh make_g4.
	
	keep doing this until table_g4 turns up empty.
	you may need to repeat all this four or five times.
	then, regenerate table_g4 with all its original entries.
		
		$ cd ../util
		$ ./make_table_g4.sh
	
	i have never had problems with make_table_g4_failures.sh,
	but it really is a pretty stupid script,
	so you should also check manually to make sure
	that none of your output files are bad.
	normally, bad files are really small.. like, hundreds of bytes.
	GEANT4 DST files should be several hundred megabytes each, if properly created.
		
		$ ls -l ../data/g4 | less
	
	there are a lot of files, but you really should skim through all the entries!
	if you find any issues, update make_table_g4_failures.sh
	and use it to regenerate table_g4
	and submit the faulty jobs again.
	
	after all this is done, ./data/g4/ should be full of 1,620 ROOT files.
	you can count them like this:
		
		$ ls -1 ../data/g4 | wc -l

RECONSTRUCT CALORIMETER CLUSTERS
	same basic idea as before.
	generate the argument table, submit the jobs, wait.
		
		$ ./make_table_rc.sh
		$ head -n 4 table_rc
		G40001103225000.root RC0001103225000.root e- 3.2 25.
		G40001103225001.root RC0001103225001.root e- 3.2 25.
		G40001103225002.root RC0001103225002.root e- 3.2 25.
		G40001103225003.root RC0001103225003.root e- 3.2 25.
		$ less table_rc
		$ cd ../condor
		$ ./submit.sh g42rc.
		$ ./checkdone.sh
		112 has not finished!
		941 has not finished!
		$ ./checkdone.sh
		112 has not finished!
		$ ./checkdone.sh
		$ cat err/0
		blah nothing worrisome blah
		$ cat err/500
		blah nothing worrisome blah
		$ cat log/333
		blah terminated correctly blah
	
	g42rc.C generally completes faster than make_g4.C,
	but it can still be over an hour.
	some stupid jobs can take several hours.
	
	i do not normally have issues with g42rc.C,
	but you will still want to check the output for weirdly small files.
	normally, these guys will be around 10 kilobytes or so.
	in particular, check for files with exactly 390 bytes.
		
		$ ls -l ../data/rc | less
		$ ls -l ../data/rc | grep -e " 390 "
	
	if you have issues, a make_table_rc_failures.sh script does exist.
	but, again, it is very stupid.
	
	one time, i had issues with some G4 jobs
	not properly closing their data files on exiting,
	and the G4 file sizes were not affected,
	but the RC jobs could not run on the broken G4 files.
	if this happens, you will need to
		
		1. generate the argument list for the failed RC jobs
		2. copy that list to table_g4
		3. delete all the RC*.root argument entries in table_g4,
		   so that it looks like a valid list of G4 arguments.
		4. delete all the broken G4 files
		5. re-generate the broken G4 files,
		   and pray that they close correctly this time.
		6. re-submit the failed RC jobs
	
	this has only happened to me once,
	so there is not script to automate the process.
	apologies.
	
	revision: actually, it has happened enough now that make_table_rc_failures.sh
	revision: checks for these broken G4 files, which i think appear as
	revision: RC files with exactly 6689 bytes. not 100% sure.
	revision: you still need to manually create the new table_g4 file.
	
	revision: RC files with exactly 6821 bytes seem to indicate the same issue.

COMPUTE ENERGY RESOLUTION
	this one is a little weird,
	'cause you need to collapse many RC files
	into a small number of DE files.
	so, in addition to an argument table,
	you need to generate the RCLI0 and RCLI1 files.
		
		$ cd ../util
		$ ./make_table_de.sh
		$ head -n 4 table_de
		00011032 DE00011032.root
		00011024 DE00011024.root
		00011016 DE00011016.root
		00011008 DE00011008.root
		$ cat table_de
		$ ./make_files_de.sh
	
	./util/make_files_de.sh should fill
	./data/de/, ./data/rcli0/, and ./data/rcli1/
		
		$ ls ../data/de
		$ ls ../data/rcli0
		$ ls ../data/rcli1
	
	the RCLI files are generated fully-formed,
	so you can check those too.
		
		$ head -n 4 ../data/rcli0/000110000064
		data/rc/RC0001100000640.root
		data/rc/RC0001100000641.root
		data/rc/RC0001100000642.root
		data/rc/RC0001100000643.root
		$ cat ../data/rcli0/000110000064
		$ head -n 4 ../data/rcli1/00011000
		000110002500 25.
		000110002120 21.2
		000110000820 8.2
		000110000400 4.0
		$ cat ../data/rcli1/00011000
	
	to actually fill the DE files,
	which right now are just skeletons,
	submit the rc2de condor job.
		
		$ cd ../condor
		$ ./submit.sh rc2de.
	
	this should not take more than a few minutes.
	be sure to check for errors when your jobs finish,
	both in your logs and in your DE file sizes.
	the DE files should be a few kilobytes each.
	size of exactly 5430 bytes probably indicates failure.
	
	also, at this point, debugging plots will start showing up in ./data/qa0/
		
		$ ls ../data/qa0
	
	these plots should all show a histogram
	that looks like a crystal ball sorta distribution.
	there should be a filled yellow gaussian,
	and there should be a non-filled gaussian.
	
	early on, i had a lot of trouble getting these to fit properly.
	you do not need to check every QA0 file every run,
	but if you get wonky-looking energy resolution values,
	then these QA0 PDF files are the plots to check.
	
	*****************************************
	*** EXTRA! EXTRA! LEARN ALL ABOUT IT! ***
	*****************************************
	*/
	* this bit, up 'til the next section "FIT ENERGY RESOLUTIONN CURVES", is optional.
	* you do not need to read it to use the code in this project,
	* but it will help you learn about how the code works
	* in case you ever need to modify or debug the code.
	*
	*****************************************
	
	this is the first time that you need to call a make_files script.
	
	each DE file contains a TNtuple.
	the CINT macro rc2de.C can compute one energy resolution,
	and it adds one entry to the TNtuple in its DE file.
	
	if you generate new data, the old TNtuple entries must be cleared.
	./util/make_files_de.sh removes the old DE files
	and creates some new ones with TNtuple's that have zero entries.
	
	rc2de.C takes multiple RC files as input.
	that is what the RCLI0 files are for.
	they are just lists of RC files
	that get combined in one call to rc2de.C
	
	if you need to prevent rc2de.C from running over a given RC file,
	e.g. because the RC file has not been properly generated,
	then you just delete the RC file's name from the appropriate RCLI0 list.
	
	several instances of rc2de.C output to the same DE file,
	but TFile is not concurrency-safe.
	so, i need to run in series all the jobs
	that output to a given DE file.
	
	that is what the RCLI1 files are for.
	they are lists of RCLI0 files, plus metadata, that get run in series.
	the RCLI1 files are read by rc2de.csh, but they are not seen by rc2de.C

FIT ENERGY RESOLUTION CURVES
	again, this collapses several DE files
	into one PA file.
	so, you need a table,
	but you also need to pre-generate your PA file.
		
		$ cd ../util
		$ ./make_table_pa.sh
		$ ./make_file_pa.sh
	
	then submit and check your condor jobs like normal.
		
		$ cd ../condor
		$ ./submit.sh de2pa.
	
	the ./data/qa1/ directory should be all filled up with PDF files.
	
	*****************************************
	*** EXTRA! EXTRA! LEARN ALL ABOUT IT! ***
	*****************************************
	
	so, you know that running ./util/make_table_pa.sh
	generates the text file ./util/table_pa.sh
	
	and, it know that i said that ./util/table
	was the source and wellspring of life for all make_table scripts,
	but that was actually a lie.
	for example, make_table_pa.sh reads table_de as input
	'cause it looks so darn similar to what table_pa needs to look like.
	some make_table and make_file[s] scripts take even dirtier shortcuts.
	
	the point is, you might run into hard-to-diagnose problems
	if you try to run these scripts
	in not exactly the right order.
	i apologize, but i was optimizing for development time
	over maintainence time,
	given the possible one-off nature of the project.
	
	you may also remember that by typing
		
		$ ./submit.sh de2pa.
	
	you are basically executing the command
		
		$ condor_submit de2pa.job
	
	./condor/de2pa.job is mostly a totally generic condor job file.
	it has two distinguishing features.
		
		1. it gets its argument list as follows:
				
				Queue Arguments From ../util/table_pa
			
			so, ./condor/de2pa.job really does directly read from ./util/table_pa
			and by modifying table_pa after table_pa is generated
			you can modify the argument list passed to de2pa.job
		
		2. its executable is set to ./condor/de2pa.csh
				
				Executable = $(Initialdir)/condor/de2pa.csh
			
			this script, ./condor/de2pa.csh, basically just calls ./macro/de2pa.C
			with some appropriate arguments.
	
	in particular, the input directory for de2pa.C is defined as ./data/de/
	and the output directory is defined as ./data/pa/
	and the directory for debugging plots is defined as ./data/qa1/

REPEAT EVERYTHING FOR XEMC JOBS
	at this point, you have computed best-fit energy resolution curves
	for a whole bunch of different pseudorapidities.
	but, now you want to combine statistics
	and get even better curves.. one for each calorimeter.
	
	so, do exactly as above, but use XEMC everywhere.
	XEMC versions of DE and PA files exist.
	for the DE files, for instance,
		
		$ cd ../util
		$ ./make_files_de_XEMC.sh
		$ ./make_table_de_XEMC.sh
		$ cd ../condor
		$ ./submit.sh rc2de_XEMC.
	
	when this completes, ./data/de_XEMC/ and ./data/qa0_XEMC/
	should be filled with crap.
	
	do the same thing for the XEMC-version PA jobs.

MAKE FINAL PLOTS
	the job is called pa2pr_XEMC.
	it has no table file and no condor job file.
	just execute it, from the top directory.
		
		$ cd ..
		$ condor/pa2pr_XEMC.csh
	
	the directory ./data/pr_XEMC/ should have a few PDF files in it now.
